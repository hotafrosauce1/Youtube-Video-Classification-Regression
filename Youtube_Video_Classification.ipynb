{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "name": "Youtube Video Classification",
    "notebookId": 1849152751397131,
    "colab": {
      "name": "Youtube Video Classification.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hotafrosauce1/Youtube-Video-Classification-Regression/blob/master/Youtube_Video_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0ZPMVkg96DC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dbutils.library.installPyPI(\"keras\")\n",
        "# dbutils.library.installPyPI(\"tensorflow\")\n",
        "# dbutils.library.installPyPI(\"image\")\n",
        "\n",
        "# dbutils.library.restartPython()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qG_7Y6Fl96DH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "427c20a8-0757-43d5-9e69-16a2ce06cb7f"
      },
      "source": [
        "# Standard Imports\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# Pipelines for training and evaluating model\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Preprocessing/Feature Extraction\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Models \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "# Scoring\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import make_scorer\n",
        "\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.backend import clear_session"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCxHwzxa96DL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converts JSON dictionary of Video Category Ids for \n",
        "# a given country into a DataFrame\n",
        "def json_to_df(path):\n",
        "    f = lambda x: x.loc['items']['snippet']['title']\n",
        "    g = lambda x: x.loc['items']['snippet']['assignable']\n",
        "    h = lambda x: x.loc['items']['id']\n",
        "    \n",
        "    df = pd.read_json(path)\n",
        "    df['Category'] = df.apply(f, axis = 1)\n",
        "    df['Assignable'] = df.apply(g, axis = 1)\n",
        "    df['Id'] = df.apply(h, axis = 1)\n",
        "    df['Id'] = df['Id'].astype(int)\n",
        "    \n",
        "    cols = ['Id', 'Category', 'Assignable']\n",
        "    \n",
        "    df = df[cols]\n",
        "    \n",
        "    return df[df['Assignable']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_efTyw6S96DO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "f6bf9126-5da9-4087-b3fc-077fc036d004"
      },
      "source": [
        "%%time\n",
        "\n",
        "countries = ['CA', 'GB', 'US']\n",
        "data = pd.DataFrame({})\n",
        "\n",
        "# Concatenating Data\n",
        "for country in countries:\n",
        "  \n",
        "    country_youtube_video_data_path = '{}videos.csv'.format(country)\n",
        "    country_category_id_path ='{}_category_id.json'.format(country)\n",
        "    \n",
        "    country_category_id_data = json_to_df(country_category_id_path)\n",
        "    country_youtube_video_data = pd.read_csv(country_youtube_video_data_path)\n",
        "    \n",
        "    country_youtube_video_data['category_id'] = country_youtube_video_data['category_id'].astype(int)\n",
        "    \n",
        "    video_data_w_category = pd.merge(country_youtube_video_data, \n",
        "                                     country_category_id_data,\n",
        "                                     left_on = 'category_id',\n",
        "                                     right_on = 'Id')\n",
        "    \n",
        "    data = pd.concat([data, video_data_w_category])\n",
        "    \n",
        "data.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.69 s, sys: 190 ms, total: 1.88 s\n",
            "Wall time: 4.32 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1ETgIhn96DT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 687
        },
        "outputId": "6b0937e5-de00-4ffd-abcc-7be63f686fa7"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_id</th>\n",
              "      <th>trending_date</th>\n",
              "      <th>title</th>\n",
              "      <th>channel_title</th>\n",
              "      <th>category_id</th>\n",
              "      <th>publish_time</th>\n",
              "      <th>tags</th>\n",
              "      <th>views</th>\n",
              "      <th>likes</th>\n",
              "      <th>dislikes</th>\n",
              "      <th>comment_count</th>\n",
              "      <th>thumbnail_link</th>\n",
              "      <th>comments_disabled</th>\n",
              "      <th>ratings_disabled</th>\n",
              "      <th>video_error_or_removed</th>\n",
              "      <th>description</th>\n",
              "      <th>Id</th>\n",
              "      <th>Category</th>\n",
              "      <th>Assignable</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>n1WpP7iowLc</td>\n",
              "      <td>17.14.11</td>\n",
              "      <td>Eminem - Walk On Water (Audio) ft. BeyoncÃ©</td>\n",
              "      <td>EminemVEVO</td>\n",
              "      <td>10</td>\n",
              "      <td>2017-11-10T17:00:03.000Z</td>\n",
              "      <td>Eminem|\"Walk\"|\"On\"|\"Water\"|\"Aftermath/Shady/In...</td>\n",
              "      <td>17158579</td>\n",
              "      <td>787425</td>\n",
              "      <td>43420</td>\n",
              "      <td>125882</td>\n",
              "      <td>https://i.ytimg.com/vi/n1WpP7iowLc/default.jpg</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Eminem's new track Walk on Water ft. BeyoncÃ© i...</td>\n",
              "      <td>10</td>\n",
              "      <td>Music</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2Vv-BfVoq4g</td>\n",
              "      <td>17.14.11</td>\n",
              "      <td>Ed Sheeran - Perfect (Official Music Video)</td>\n",
              "      <td>Ed Sheeran</td>\n",
              "      <td>10</td>\n",
              "      <td>2017-11-09T11:04:14.000Z</td>\n",
              "      <td>edsheeran|\"ed sheeran\"|\"acoustic\"|\"live\"|\"cove...</td>\n",
              "      <td>33523622</td>\n",
              "      <td>1634130</td>\n",
              "      <td>21082</td>\n",
              "      <td>85067</td>\n",
              "      <td>https://i.ytimg.com/vi/2Vv-BfVoq4g/default.jpg</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>ðŸŽ§: https://ad.gt/yt-perfect\\nðŸ’°: https://atlant...</td>\n",
              "      <td>10</td>\n",
              "      <td>Music</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>H1KBHFXm2Bg</td>\n",
              "      <td>17.14.11</td>\n",
              "      <td>21 Savage - Bank Account (Official Music Video)</td>\n",
              "      <td>21 Savage</td>\n",
              "      <td>10</td>\n",
              "      <td>2017-11-10T19:00:02.000Z</td>\n",
              "      <td>21 savage|\"bank account\"|\"21 savage bank accou...</td>\n",
              "      <td>5068229</td>\n",
              "      <td>263596</td>\n",
              "      <td>8585</td>\n",
              "      <td>28976</td>\n",
              "      <td>https://i.ytimg.com/vi/H1KBHFXm2Bg/default.jpg</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Watch the official music video of Bank Account...</td>\n",
              "      <td>10</td>\n",
              "      <td>Music</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7MxiQ4v0EnE</td>\n",
              "      <td>17.14.11</td>\n",
              "      <td>Daang ( Full Video ) | Mankirt Aulakh | Sukh S...</td>\n",
              "      <td>Speed Records</td>\n",
              "      <td>10</td>\n",
              "      <td>2017-11-11T16:41:15.000Z</td>\n",
              "      <td>punjabi songs|\"punjabi bhangra\"|\"punjabi music...</td>\n",
              "      <td>5718766</td>\n",
              "      <td>127477</td>\n",
              "      <td>7134</td>\n",
              "      <td>8063</td>\n",
              "      <td>https://i.ytimg.com/vi/7MxiQ4v0EnE/default.jpg</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Song - Daang\\nSinger - Mankirt Aulakh\\nFaceboo...</td>\n",
              "      <td>10</td>\n",
              "      <td>Music</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>j67FgNEvyh8</td>\n",
              "      <td>17.14.11</td>\n",
              "      <td>Telefoon || Babbu Maan || Promo || Full Song 1...</td>\n",
              "      <td>Hey Yolo</td>\n",
              "      <td>10</td>\n",
              "      <td>2017-11-12T04:24:34.000Z</td>\n",
              "      <td>Telefoon|\"Babbu Maan\"|\"Mehfil Mitran Di\"|\"new ...</td>\n",
              "      <td>178447</td>\n",
              "      <td>4339</td>\n",
              "      <td>96</td>\n",
              "      <td>876</td>\n",
              "      <td>https://i.ytimg.com/vi/j67FgNEvyh8/default.jpg</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Full Song Out Now 15th November\\n\\nHey Yolo, S...</td>\n",
              "      <td>10</td>\n",
              "      <td>Music</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      video_id trending_date  ... Category Assignable\n",
              "0  n1WpP7iowLc      17.14.11  ...    Music       True\n",
              "1  2Vv-BfVoq4g      17.14.11  ...    Music       True\n",
              "2  H1KBHFXm2Bg      17.14.11  ...    Music       True\n",
              "3  7MxiQ4v0EnE      17.14.11  ...    Music       True\n",
              "4  j67FgNEvyh8      17.14.11  ...    Music       True\n",
              "\n",
              "[5 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHqcSnWB96DW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "34b0c68a-717c-4ba3-b2a8-ee00249c88a8"
      },
      "source": [
        "le = LabelEncoder()\n",
        "X, y = data.drop(['Category'], axis = 1), data['Category']\n",
        "y = le.fit_transform(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, random_state = 420)\n",
        "\n",
        "print('Dataset Length: {}'.format(len(X)),'Training Data Length: {}'.format(len(X_train)),'Number of Response Categories: {}'.format(len(np.unique(y_train))))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset Length: 120375 Training Data Length: 90281 Number of Response Categories: 15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvFmWYUF96DZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "ded099d5-fc46-4177-8a95-4253dcfb1765"
      },
      "source": [
        "%%time\n",
        "\n",
        "def get_thumbnail(url): \n",
        "    r = requests.get(url).content\n",
        "    img_data = Image.open(BytesIO(r))\n",
        "    img_data = img_data.resize((50, 50))\n",
        "    \n",
        "    return np.array(img_data).reshape(1, 50, 50, 3)\n",
        "\n",
        "# Download the Video thumbnails to use to predict video's category\n",
        "img_data = X_train['thumbnail_link'].map(get_thumbnail)\n",
        "\n",
        "img_data.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 16min 58s, sys: 50.3 s, total: 17min 49s\n",
            "Wall time: 26min 50s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWKmrj4096Dc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "36f8ed1c-af73-4103-e078-257f69304bdd"
      },
      "source": [
        "# Change shape of training data so it can be fed into model\n",
        "img_data = np.concatenate([img_data.iloc[i] for i in range(len(img_data))])\n",
        "img_data.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(90281, 50, 50, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s40R7S9Q96Df",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "outputId": "5bc6c1d7-d2ef-44eb-a3d7-c8e81aec8f61"
      },
      "source": [
        "# Convert class labels into class vectors\n",
        "y_train_img_model = np.array([y_train[i]\n",
        "                              for i in range(len(y_train))\n",
        "                            ])\n",
        "                              \n",
        "y_train_img_model = keras.utils.to_categorical(y_train_img_model, num_classes = 15)\n",
        "y_train_img_model"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bx14AWem96Di",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dictionary to store different models' performances\n",
        "model_dict = {'Model':[], 'Training Acc.':[], 'Validation Acc.':[]}\n",
        "\n",
        "# Return training error and validation error for model\n",
        "def get_train_val_error(model):\n",
        "    scorer = make_scorer(accuracy_score)\n",
        "    \n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    preds = model.predict(X_train)\n",
        "    training_acc = accuracy_score(y_train, preds)\n",
        "    val_acc = np.mean(cross_val_score(model, X_train, y_train, scoring = scorer))\n",
        "\n",
        "    return training_acc, val_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNmKiUtL96Dm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "eac3e985-5547-4db0-f56d-bcdd09291ce5"
      },
      "source": [
        "cols = ['title', 'tags', 'description']\n",
        "\n",
        "# Data Pipeline for text-based model\n",
        "model_text = Pipeline([\n",
        "    ('Columns', ColumnTransformer([\n",
        "        ('keep', 'passthrough', cols)\n",
        "    ])),\n",
        "    ('Imputation', SimpleImputer(strategy = 'constant', fill_value = '')),\n",
        "    ('Bag of Words', ColumnTransformer([\n",
        "        (cols[0], CountVectorizer(stop_words = 'english', max_features = 10000), 0),\n",
        "        (cols[1], CountVectorizer(stop_words = 'english', max_features = 10000), 1),\n",
        "        (cols[2], CountVectorizer(stop_words = 'english', max_features = 10000), 2)\n",
        "    ])),\n",
        "    ('TF-IDF', TfidfTransformer()),\n",
        "    ('Model Text', LogisticRegression(multi_class = 'multinomial', solver = 'sag'))\n",
        "])\n",
        "\n",
        "model_text"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('Columns',\n",
              "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
              "                                   sparse_threshold=0.3,\n",
              "                                   transformer_weights=None,\n",
              "                                   transformers=[('keep', 'passthrough',\n",
              "                                                  ['title', 'tags',\n",
              "                                                   'description'])],\n",
              "                                   verbose=False)),\n",
              "                ('Imputation',\n",
              "                 SimpleImputer(add_indicator=False, copy=True, fill_value='',\n",
              "                               missing_values=nan, strategy='constant',\n",
              "                               verbose=0)),\n",
              "                ('Bag of Wor...\n",
              "                ('TF-IDF',\n",
              "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
              "                                  sublinear_tf=False, use_idf=True)),\n",
              "                ('Model Text',\n",
              "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='multinomial', n_jobs=None,\n",
              "                                    penalty='l2', random_state=None,\n",
              "                                    solver='sag', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtTZIasm96Dp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "752fb4d8-13ab-4d64-cbd9-03829ebf48af"
      },
      "source": [
        "# Get training and validation error of text-based model\n",
        "model_text_train_err, model_text_val_err = get_train_val_error(model_text)\n",
        "\n",
        "print('Training Accuracy: {}'.format(model_text_train_err))\n",
        "print('Validation Accuracy: {}'.format(model_text_val_err))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy: 0.9650646315393051\n",
            "Validation Accuracy: 0.9418039632729999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnCol_Mv96Dv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add text-based model's performance to the model dictionary\n",
        "model_dict['Model'].append('Text Model (Baseline)')\n",
        "model_dict['Training Acc.'].append(model_text_train_err)\n",
        "model_dict['Validation Acc.'].append(model_text_val_err)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pWn1QWG96Dy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "f8547cd8-265a-41d5-87cd-6e9f09db04a7"
      },
      "source": [
        "# Clear previous model weights and returns a blank baseline CNN model\n",
        "# consisting of 10 feature maps, a 3x3 local receptive field, and the ReLU\n",
        "# activaton function\n",
        "def baseline_image_model():\n",
        "    clear_session()\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(10, (3, 3), activation='relu', input_shape = (50, 50, 3)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(15, activation='softmax'))\n",
        "\n",
        "    sgd = SGD(lr=0.001)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics = ['accuracy'])\n",
        "    \n",
        "    return model\n",
        "\n",
        "image_model = baseline_image_model()\n",
        "image_model"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.sequential.Sequential at 0x7f47bc214780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncEKqpFt96D0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "outputId": "4ac8f9ee-36d1-477f-8655-3393ea9a5264"
      },
      "source": [
        "# Return validation accuracies for image-based model\n",
        "def cross_val_score_custom(X_train_img, y_train_img):\n",
        "    from sklearn.model_selection import KFold\n",
        "    \n",
        "    kfold = KFold(n_splits = 3)\n",
        "    val_accs = []\n",
        "    \n",
        "    for train_index, val_index in kfold.split(X_train_img):\n",
        "        new_model = baseline_image_model()\n",
        "        \n",
        "        new_model.fit(X_train_img[train_index],\n",
        "                      y_train_img[train_index],\n",
        "                      epochs = 5,\n",
        "                      batch_size = 128)\n",
        "        \n",
        "        val_error, val_acc = new_model.evaluate(X_train_img[val_index], y_train_img[val_index])\n",
        "        val_accs.append(val_acc)\n",
        "        \n",
        "    return val_accs\n",
        "\n",
        "# Return training and validation accuracy of image-based model\n",
        "def get_train_val_error_image_model(image_model):\n",
        "    image_model.fit(img_data / 255, y_train_img_model, epochs = 5)\n",
        "    \n",
        "    train_err, train_acc = image_model.evaluate(img_data / 255, y_train_img_model)\n",
        "    val_acc = np.mean(cross_val_score_custom(img_data / 255, y_train_img_model))\n",
        "    \n",
        "    return train_acc, val_acc\n",
        "\n",
        "\n",
        "# Get training and validation error of image-based model\n",
        "train_acc_image_model, val_acc_image_model = get_train_val_error_image_model(image_model)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "90281/90281 [==============================] - 53s 588us/step - loss: 2.1734 - accuracy: 0.3280\n",
            "Epoch 2/5\n",
            "90281/90281 [==============================] - 54s 599us/step - loss: 2.0213 - accuracy: 0.3572\n",
            "Epoch 3/5\n",
            "90281/90281 [==============================] - 54s 598us/step - loss: 1.9409 - accuracy: 0.3759\n",
            "Epoch 4/5\n",
            "90281/90281 [==============================] - 54s 604us/step - loss: 1.8708 - accuracy: 0.3998\n",
            "Epoch 5/5\n",
            "90281/90281 [==============================] - 54s 595us/step - loss: 1.8063 - accuracy: 0.4239\n",
            "90281/90281 [==============================] - 28s 311us/step\n",
            "Epoch 1/5\n",
            "60187/60187 [==============================] - 30s 493us/step - loss: 2.2595 - accuracy: 0.3072\n",
            "Epoch 2/5\n",
            "60187/60187 [==============================] - 29s 476us/step - loss: 2.1839 - accuracy: 0.3273\n",
            "Epoch 3/5\n",
            "60187/60187 [==============================] - 29s 485us/step - loss: 2.1308 - accuracy: 0.3352\n",
            "Epoch 4/5\n",
            "60187/60187 [==============================] - 29s 489us/step - loss: 2.0857 - accuracy: 0.3421\n",
            "Epoch 5/5\n",
            "60187/60187 [==============================] - 29s 480us/step - loss: 2.0562 - accuracy: 0.3473\n",
            "30094/30094 [==============================] - 7s 247us/step\n",
            "Epoch 1/5\n",
            "60187/60187 [==============================] - 29s 484us/step - loss: 2.2560 - accuracy: 0.3073\n",
            "Epoch 2/5\n",
            "60187/60187 [==============================] - 29s 486us/step - loss: 2.1768 - accuracy: 0.3345\n",
            "Epoch 3/5\n",
            "60187/60187 [==============================] - 29s 487us/step - loss: 2.1327 - accuracy: 0.3428\n",
            "Epoch 4/5\n",
            "60187/60187 [==============================] - 29s 478us/step - loss: 2.0952 - accuracy: 0.3461\n",
            "Epoch 5/5\n",
            "60187/60187 [==============================] - 29s 489us/step - loss: 2.0603 - accuracy: 0.3513\n",
            "30094/30094 [==============================] - 8s 260us/step\n",
            "Epoch 1/5\n",
            "60188/60188 [==============================] - 30s 490us/step - loss: 2.2511 - accuracy: 0.3157\n",
            "Epoch 2/5\n",
            "60188/60188 [==============================] - 29s 475us/step - loss: 2.1656 - accuracy: 0.3379\n",
            "Epoch 3/5\n",
            "60188/60188 [==============================] - 29s 483us/step - loss: 2.1155 - accuracy: 0.3456\n",
            "Epoch 4/5\n",
            "60188/60188 [==============================] - 29s 487us/step - loss: 2.0754 - accuracy: 0.3491\n",
            "Epoch 5/5\n",
            "60188/60188 [==============================] - 30s 493us/step - loss: 2.0388 - accuracy: 0.3512\n",
            "30093/30093 [==============================] - 8s 250us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mKI72XR96D3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "15af7d6a-10b6-4323-b84a-2bc1eaf60b59"
      },
      "source": [
        "print('Training accuracy for baseline image-based model: {}'.format(train_acc_image_model))\n",
        "print('Validation accuracy for baseline image-based model: {}'.format(val_acc_image_model))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training accuracy for baseline image-based model: 0.4494079649448395\n",
            "Validation accuracy for baseline image-based model: 0.335342009862264\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeKO6RJv96D5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add image-based model's performance to the model dictionary\n",
        "\n",
        "model_dict['Model'].append('Img Model (Baseline)')\n",
        "model_dict['Training Acc.'].append(train_acc_image_model)\n",
        "model_dict['Validation Acc.'].append(val_acc_image_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HlCMZ2s96D9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "9151fcc1-980b-424b-9678-24b48ffb2c73"
      },
      "source": [
        "model_performance = pd.DataFrame(model_dict, index = model_dict['Model'])\n",
        "model_performance"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Training Acc.</th>\n",
              "      <th>Validation Acc.</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Text Model (Baseline)</th>\n",
              "      <td>Text Model (Baseline)</td>\n",
              "      <td>0.965065</td>\n",
              "      <td>0.941804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Img Model (Baseline)</th>\n",
              "      <td>Img Model (Baseline)</td>\n",
              "      <td>0.449408</td>\n",
              "      <td>0.335342</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       Model  Training Acc.  Validation Acc.\n",
              "Text Model (Baseline)  Text Model (Baseline)       0.965065         0.941804\n",
              "Img Model (Baseline)    Img Model (Baseline)       0.449408         0.335342"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3YJwn9496EB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "fc1d8275-8fe2-4396-f301-2ca88b37935d"
      },
      "source": [
        "pos = list(range(len(model_performance))) \n",
        "width = 0.25 \n",
        "fig, ax = plt.subplots(figsize = (12,6))\n",
        "\n",
        "plt.bar(pos, \n",
        "        model_performance['Training Acc.'], \n",
        "        width, \n",
        "        alpha=0.5, \n",
        "        color='#EE3224', \n",
        "        align = 'center',\n",
        "        label=model_performance['Model'][0]) \n",
        "plt.bar([p + width for p in pos], \n",
        "        model_performance['Validation Acc.'],\n",
        "        width, \n",
        "        alpha=0.5, \n",
        "        color='#F78F1E',\n",
        "        align = 'center',\n",
        "        label=model_performance['Model'][1]) \n",
        "\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.set_title('Training and Validation Accuracies for Img and Text-based Models')\n",
        "ax.set_xticks([p + 0.5 * width for p in pos])\n",
        "ax.set_xticklabels(model_performance['Model'], ha = 'center')\n",
        "\n",
        "plt.legend(['Training Acc.', 'Validation Acc.'], loc='upper right')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f47bccda6a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HM4jbIeHhx4Z",
        "colab_type": "text"
      },
      "source": [
        "## Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pftx79K2iLvx",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "*   Text-based model (Baseline)\n",
        "            Training Accuracy: 96.50%\n",
        "            Validation Accuracy: 94.18%\n",
        "\n",
        "*   Image-based model (Baseline)\n",
        "            Training Accuracy: 44.94%\n",
        "            Validation Accuracy: 33.53%\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUhVtYODh9_n",
        "colab_type": "text"
      },
      "source": [
        "# To-do"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Axm_HwjbjVnN",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "*   Train/test a more complex text-based model than baseline model (ANN, CNN, SVM)\n",
        "*   Train/test a more complex CNN architecture for image-based model\n",
        "\n"
      ]
    }
  ]
}